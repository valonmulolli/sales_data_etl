# Sales Data ETL Pipeline ğŸ“ŠğŸš€

## ğŸŒ Project Overview
A cutting-edge, containerized Python ETL (Extract, Transform, Load) pipeline designed for robust sales data processing, analysis, and cloud-native deployment.

## âœ¨ Key Features
- ğŸ” Advanced Data Extraction
  - CSV input parsing
  - Flexible data source support
- ğŸ›¡ï¸ Comprehensive Data Validation
  - Type checking
  - Data quality scoring
  - Error handling
- ğŸ§® Sales Metrics Calculation
  - Daily and aggregate sales analysis
  - Performance tracking
- ğŸ—„ï¸ Multi-destination Data Loading
  - PostgreSQL database integration
  - CSV file output
  - Data archiving
- ğŸ“ˆ Monitoring & Logging
  - Detailed performance metrics
  - System resource tracking
  - Configurable logging levels

## ğŸ› ï¸ Tech Stack
- **Languages**: Python 3.12
- **Database**: PostgreSQL
- **ORM**: SQLAlchemy
- **Containerization**: Docker
- **Migration**: Alembic
- **Monitoring**: Custom metrics tracking

## ğŸš€ Quick Start

### Prerequisites
- Docker
- Docker Compose
- Python 3.8+
- Git

### Installation & Setup
```bash
# Clone the repository
git clone https://github.com/valonmulolli/sales_data_etl.git
cd sales_data_etl

# Build and run with Docker
docker-compose up --build
```

### Local Development
```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run ETL Pipeline
python main.py
```

## ğŸ§ª Testing
```bash
# Run unit tests
python -m pytest tests/

# Run integration tests
./run_integration_tests.sh
```

## ğŸ“‹ Configuration
Key configuration files:
- `config.py`: Main configuration settings
- `.env`: Environment-specific variables
- `docker-compose.yml`: Container orchestration

### Environment Variables
```
# Database Configuration
DB_HOST=postgres
DB_PORT=5432
DB_USER=etl_user
DB_PASSWORD=etl_password
DB_NAME=sales_db

# ETL Pipeline Settings
ENV=production
LOG_LEVEL=INFO
```

## ğŸ” Security Considerations
- Secrets management via environment variables
- Minimal Docker image footprint
- Secure database connection handling

## ğŸ“Š Monitoring Capabilities
- Detailed ETL pipeline performance tracking
- System resource utilization monitoring
- Optional Slack/Email alerting

## ğŸŒˆ Future Roadmap
- [ ] Machine learning-based anomaly detection
- [ ] Advanced error recovery mechanisms
- [ ] Multi-cloud deployment support
- [ ] Enhanced data visualization

## ğŸ¤ Contributing
1. Fork the repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“œ License
MIT License

## ğŸ‘¥ Contact
- GitHub: [@valonmulolli](https://github.com/valonmulolli)
